outlierTest(lm1)
influencePlot(lm1)
train_PG <- train_PG %>%  filter(!row_number() %in% c(70, 967, 1012, 1025, 1030))
lm1 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm1)
plot(lm1)
outlierTest(lm1)
influencePlot(lm1)
train_PG <- train_PG %>%  filter(!row_number() %in% c(70, 967, 1012, 1025, 1030))
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:12,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
lm3 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
#lm3 = lm(log(salary)~Age+FT.+MPG,train2)
#summary(lm3)
#plot(lm3)
regular_stats_model = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+FGPG+FGAPG+`3PPG`+`3PAPG` + FTAPG, data = train)
summary(model1)
plot(model1)
lm1 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm1)
plot(lm1)
lm1 = lm(Salary~.,train_PG)
summary(lm1)
plot(lm1)
lm1 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm1)
plot(lm1)
outlierTest(lm1)
influencePlot(lm1)
train_PG <- train_PG %>%  filter(!row_number() %in% c(435, 587, 711, 972, 1008))
View(train_PG)
View(train_PG)
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
data <- read_excel("data.xlsx")
data
set.seed(1234)
shuffle = sample.int(nrow(data))
data$split = cut(shuffle, breaks=5, labels=c("1", "2", "3", "4", "test"))
train = subset(data, split != "test", select = -split)
test = subset(data, split == "test", select = -split)
data = subset(data, select = -split)
hist(data$`% of Cap`)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
library(reticulate)
library(corrplot)
library(car)
library(magrittr)
library(dplyr)
# NBA data from 1995-2017
data <- read_excel('data.xlsx')
data <- data[data[,"GP"] >= 30,]
data_reduced = data[,c('Salary', 'Pos', 'ORPG', 'DRPG', 'RPG', 'APG', 'SPG', 'BPG', 'TPG', 'PFPG', 'PPG', 'FGPG', 'FGAPG', '3PPG', '3PAPG', '2PPG', '2PAPG', 'FTPG', 'FTAPG')]
# data <- read.csv(file = 'final_dataset2.csv')
# data = data[data[,"G"] >= 30,]      #screen out less statistically significant data points
# data = data[data[,"Age"] >= 22,]    #salary cap
# data_reduced = data[,c('X','Player', 'Pos', 'salary','Age','FG.','FT.','MPG','PPG','APG','RPG','TOPG','BPG','SPG')]
# data_reduced = data_reduced[-c(which(data_reduced$Pos == "SF-SG")),]
set.seed(1234)
shuffle = sample.int(nrow(data_reduced))
data_reduced$split = cut(shuffle, breaks = 5, labels = c("1","2","3","4","test"))
train = subset(data_reduced, split != "test", select = -split)
test = subset(data_reduced, split == "test", select = -split)
data_reduced = subset(data_reduced, select = -split)
shuffle = sample.int(nrow(data))
data$split = cut(shuffle, breaks = 5, labels = c("1", "2", "3", "4", "test"))
train1 = subset(data, split != "test", select = -split)
test1 = subset(data, split == "test", select = -split)
advanced_train <- train1[,c('Salary','PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP')]
regular_train <- train1[,c('Salary','ORPG', 'DRPG', 'RPG', 'APG', 'SPG', 'BPG', 'TPG', 'PFPG', 'PPG', 'FGPG', 'FGAPG', '3PPG', '3PAPG', '2PPG', '2PAPG', 'FTPG', 'FTAPG')]
advanced_test <- test1[,c('Salary','PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP')]
regular_test <- test1[,c('Salary','ORPG', 'DRPG', 'RPG', 'APG', 'SPG', 'BPG', 'TPG', 'PFPG', 'PPG', 'FGPG', 'FGAPG', '3PPG', '3PAPG', '2PPG', '2PAPG', 'FTPG', 'FTAPG')]
par(mfrow=c(1,3))
hist(train$Salary,freq = F, main = "Salary", xlab = "Salary")
hist(log(train$Salary),freq = F, main = "Log of Salary", xlab = "Log of Salary")
hist(sqrt(train$Salary),freq = F, main = "Square Root of Salary", xlab = "Square Root of Salary of Salary")
corrplot(cor(train[,]), method = 'number', number.cex = 0.9)
total_model = lm(Salary~., data = train)
summary(total_model)
total_model = lm(Salary~., data = train)
summary(total_model)
regular_stats_model = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+FGPG+FGAPG+`3PPG`+`3PAPG` + FTAPG, data = train)
summary(model1)
plot(model1)
model2 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+FGPG+FGAPG+`3PPG`+`3PAPG`+FTAPG, data = train)
summary(model2)
plot(model2)
model2 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+FGPG+FGAPG+`3PPG`+`3PAPG`+FTAPG, data = train)
summary(model2)
plot(model2)
model3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+FGPG+FGAPG+`3PPG`+`3PAPG`+FTAPG, data = train)
summary(model3)
plot(model3)
vif(model3)
reduced_model3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train)
summary(reduced_model3)
plot(reduced_model3)
vif(reduced_model3)
train_PG =  train[train[,2] == "1", ]
train_PF =  train[train[,2] == "4", ]
train_SF =  train[train[,2] == "3", ]
train_C = train[train[,2] == "5", ]
train_SG = train[train[,2] == "2", ]
test_PG =  test[test[,2] == "1", ]
test_PF =  test[test[,2] == "4", ]
test_SF =  test[test[,2] == "3", ]
test_C = test[test[,2] == "5", ]
test_SG = test[test[,2] == "2", ]
corrplot(cor(train_PG[,-c(2, 3)]), method = 'number', number.cex = 0.8)
lm1 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm1)
plot(lm1)
outlierTest(lm1)
influencePlot(lm1)
#train_PG <- train_PG %>%  filter(!row_number() %in% c(435, 587, 711, 972, 1008))
outlierTest(lm1)
influencePlot(lm1)
train_PG <- train_PG %>%  filter(!row_number() %in% c(70, 967, 1012, 1025, 1030))
lm2 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm2)
plot(lm2)
lm2 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm2)
plot(lm2)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10, rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
lm3 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
#lm3 = lm(log(salary)~Age+FT.+MPG,train2)
#summary(lm3)
#plot(lm3)
rs$which[which.min(rs$cp),]
rs$which[which.min(rs$bic)]
rs$which[which.min(rs$cp),]
rs$which[which.min(rs$cp),]
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10, rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_PG)
summary(lm3)
plot(lm3)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10, rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_PG)
summary(lm3)
plot(lm3)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*SPG*BPG*TPG*PPG*FTAPG + I(ORPG^2) + I(DRPG^2)+ I(APG^2)+ I(SPG^2)+ I(BPG^2)+ I(TPG^2)+ I(PPG^2)+ I(FTAPG^2), data = train_PG)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*SPG*BPG*TPG*PPG*FTAPG + I(ORPG^2) + I(DRPG^2)+ I(APG^2)+ I(SPG^2)+ I(BPG^2)+ I(TPG^2)+ I(PPG^2)+ I(FTAPG^2), data = train_PG)
#not transform a low p-value of heteroscedasticity
lm4 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_PG)
bptest(lm4, ~ ORPG*DRPG*APG*SPG*BPG*TPG*PPG*FTAPG + I(ORPG^2) + I(DRPG^2)+ I(APG^2)+ I(SPG^2)+ I(BPG^2)+ I(TPG^2)+ I(PPG^2)+ I(FTAPG^2), data = train_PG)
#no sign of multicollinearity
library(car)
vif(lm3)
b = regsubsets(log(salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train2)
rs = summary(b)
lm5 = lm(log(train2$salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG,train2)
step(lm5)
lm6 = lm(log(salary)~Age+FT.+PPG + RPG,train2)
summary(lm6)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10, rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
step(lm2)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$salary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$Salary))
rmse(predict(lm3,test_PG),log(test_PG$Salary))
rmse(predict(lm6,test_PG),log(test_PG$Salary))
b = regsubsets(log(Salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train_PG)
```{r}
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$Salary))
rmse(predict(lm3,test_PG),log(test_PG$Salary))
rmse(predict(lm6,test_PG),log(test_PG$Salary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$Salary))
rmse(predict(lm3,test_PG),log(test_PG$Salary))
rmse(predict(lm6,test_PG),log(test_PG$Salary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$Salary))
rmse(predict(lm3,test_PG),log(test_PG$Salary))
rmse(predict(lm6,test_PG),log(test_PG$Salary))
#no sign of multicollinearity
library(car)
vif(lm3)
lm1 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm1)
plot(lm1)
lm2 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_PG)
summary(lm2)
plot(lm2)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_PG, nvmax=13)
rs = summary(b)
rs
plot(1:10, rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data=train_PG)
summary(lm3)
plot(lm3)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_PG)
summary(lm3)
plot(lm3)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*SPG*BPG*TPG*PPG*FTAPG + I(ORPG^2) + I(DRPG^2)+ I(APG^2)+ I(SPG^2)+ I(BPG^2)+ I(TPG^2)+ I(PPG^2)+ I(FTAPG^2), data = train_PG)
#not transform a low p-value of heteroscedasticity
lm4 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_PG)
bptest(lm4, ~ ORPG*DRPG*APG*SPG*BPG*TPG*PPG*FTAPG + I(ORPG^2) + I(DRPG^2)+ I(APG^2)+ I(SPG^2)+ I(BPG^2)+ I(TPG^2)+ I(PPG^2)+ I(FTAPG^2), data = train_PG)
#no sign of multicollinearity
library(car)
vif(lm3)
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_PG),log(test_PG$Salary))
rmse(predict(lm3,test_PG),log(test_PG$Salary))
rmse(predict(lm5,test_PG),log(test_PG$Salary))
library(corrplot)
corrplot(cor(train_C[,-c(1,2,3)]), method = 'number')
lm1 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PPG+FTAPG,train_C)
summary(lm1)
plot(lm1)
library(car)
outlierTest(lm1)
influencePlot(lm1)
train2 = subset(train_C, train_C$X != 77 & train_C$X != 97 & train_C$X != 112 & train_C$X != 309 & train_C$X != 333)
library(car)
outlierTest(lm1)
influencePlot(lm1)
train_C <- train_C %>%  filter(!row_number() %in% c(37, 100, 139, 281, 367, 1045))
library(leaps)
b = regsubsets(log(Salary)~train_PG <- train_PG %>%  filter(!row_number() %in% c(70, 967, 1012, 1025, 1030)), data = train_C)
lm2 = lm(log(salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_C)
lm2 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_C)
summary(lm2)
plot(lm2)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(salary)~Age+FG.+FT.+MPG+PPG+APG+RPG+TOPG+BPG+SPG, data = train_C)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_C)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(log(salary)~Age + FG. + FT.+ MPG + APG,train_C)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_C)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(log(Salary)~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
summary(lm3)
plot(lm3)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*BPG*TPG*PPG + I(ORPG^2) + I(DRPG^2) + I(APG^2) + I(BPG^2) + I(TPG^2) + I(PPG^2), data = train2)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*BPG*TPG*PPG + I(ORPG^2) + I(DRPG^2) + I(APG^2) + I(BPG^2) + I(TPG^2) + I(PPG^2), data = train_C)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_C)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
summary(lm3)
plot(lm3)
#not transform leads to a low p-value of heteroscedasticity
lm4 = lm(salary~ORPG+DRPG+APG+BPG+TPG+PPG,train2)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*BPG*TPG*PPG + I(ORPG^2) + I(DRPG^2) + I(APG^2) + I(BPG^2) + I(TPG^2) + I(PPG^2), data = train_C)
#not transform leads to a low p-value of heteroscedasticity
lm4 = lm(Salary~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
bptest(lm4, ~ OORPG*DRPG*APG*BPG*TPG*PPG + I(ORPG^2) + I(DRPG^2) + I(APG^2) + I(BPG^2) + I(TPG^2) + I(PPG^2), data = train_C)
#not transform leads to a low p-value of heteroscedasticity
lm4 = lm(Salary~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
bptest(lm4, ~ ORPG*DRPG*APG*BPG*TPG*PPG + I(ORPG^2) + I(DRPG^2) + I(APG^2) + I(BPG^2) + I(TPG^2) + I(PPG^2), data = train_C)
#no sign of multicollinearity
library(car)
vif(lm3)
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_C),log(test_C$salary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_C),log(test_CSalary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,test_C),log(test_C$Salary))
rmse(predict(lm3,test_C),log(test_C$Salary))
rmse(predict(lm6,test_C),log(test_C$Salary))
lm5 = lm(log(train2$salary)~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
lm5 = lm(log(Salary)~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
step(lm5)
lm6 = lm(log(salary)~ Age+FG.+FT.+RPG,train_C)
lm5 = lm(log(Salary)~ORPG+DRPG+APG+BPG+TPG+PPG,train_C)
step(lm5)
library(corrplot)
corrplot(cor(train_SG[,-c(1,2,3)]), method = 'number')
lm1 = lm(log(Salary)~Age+FG.+FT.+MPG+PPG+APG+RPG+TOPG+BPG+SPG,train_SG)
lm1 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm1)
plot(lm1)
lm1 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm1)
plot(lm1)
library(car)
outlierTest(lm1)
influencePlot(lm1)
library(car)
outlierTest(lm1)
influencePlot(lm1)
train_C <- train_C %>%  filter(!row_number() %in% c(21, 250, 396, 580, 933, 1012))
lm2 = lm(sqrt(train2$salary)~Age+FG.+FT.+MPG+PPG+APG+RPG+TOPG+BPG+SPG,train2)
summary(lm2)
plot(lm2)
lm2 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
lm2 = lm(sqrt(train_SG$Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
lm2 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
lm2 = lm(log(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
lm2 = lm((Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
lm2 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG,train_SG)
summary(lm2)
plot(lm2)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(log(salary)~Age + MPG + PPG,train2)
summary(lm3)
plot(lm3)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(1:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(log(salary)~Age + MPG + PPG,train2)
summary(lm3)
plot(lm3)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(log(salary)~ORPG+DrPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(sqrt(Slary)~ORPG+DrPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(sqrt(Salary)~ORPG+DrPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
#AIC and Mallow's Cp select model yields the same model
library(leaps)
b = regsubsets(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG+`3PAPG`+FTAPG, data = train_SG)
rs = summary(b)
plot(2:9,rs$cp, ylab = "CP statistic", xlab = "Number of Parameters")
abline(0,1)
rs$which[which.min(rs$cp),]
#step(lm2)
lm3 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
summary(lm3)
plot(lm3)
#no sign of heteroscedasticity
library(lmtest)
bptest(lm3, ~ ORPG*DRPG*APG*SPG*BPG+TPG*PFPG*PPG + I(ORPG^2)+I(DRPG^2)+I(APG^2)+I(SPG^2)+I(BPG^2)+I(TPG^2)+I(PFPG^2)+I(PPG^2), data = train_SG)
#not transform leads to a low p-value of heteroscedasticity
lm4 = lm(Salary~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
bptest(lm4, ~ ORPG*DRPG*APG*SPG*BPG+TPG*PFPG*PPG + I(ORPG^2)+I(DRPG^2)+I(APG^2)+I(SPG^2)+I(BPG^2)+I(TPG^2)+I(PFPG^2)+I(PPG^2), data = train_SG)
#not a sign of multicollinearity
library(car)
vif(lm3)
b = regsubsets(log(salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train2)
rs = summary(b)
lm5 = lm(sqrt(train2$salary)~AORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
b = regsubsets(log(salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train2)
rs = summary(b)
lm5 = lm(sqrt(Salary)~AORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
b = regsubsets(log(salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train2)
rs = summary(b)
lm5 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
#step(lm5)
lm6 = lm(log(salary)~ Age + PPG,train2)
summary(lm6)
b = regsubsets(log(salary)~Age+FG.+FT.+PPG+APG+RPG+TOPG+BPG+SPG, data = train2)
rs = summary(b)
lm5 = lm(sqrt(Salary)~ORPG+DRPG+APG+SPG+BPG+TPG+PFPG+PPG,train_SG)
summary(lm5)
#step(lm5)
lm6 = lm(log(salary)~ Age + PPG,train2)
summary(lm6)
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,train_SG),log(train_SG$salary))
#compare rmse for original model and reduced model
rmse=function(x,y){sqrt(mean((x-y)^2))}
rmse(predict(lm2,train_SG),log(train_SG$Salary))
rmse(predict(lm3,train_SG),log(train_SG$Salary))
rmse(predict(lm6,train_SG),log(train_SG$Salary))
